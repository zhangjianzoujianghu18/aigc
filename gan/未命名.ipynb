{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6e1055d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/waj/anaconda3/envs/tts/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1 import package\n",
    "import torch\n",
    "import  torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abbf7419",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=512\n",
    "EPOCHS=200\n",
    "image_size=28\n",
    "channel=1\n",
    "z_dim=128\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2127e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mnist_image(image_array, label):\n",
    "    plt.imshow(image_array, cmap='Greys')\n",
    "    plt.title(f\"Label: {label}\")\n",
    "# 1 data loader \n",
    "dataset=datasets.MNIST(\"../data/\",train=True,transform=transforms.Compose([\n",
    "    transforms.Resize(28),transforms.ToTensor(),transforms.Normalize(0.5,0.5)\n",
    "]))\n",
    "mnist=DataLoader(dataset,shuffle=True,batch_size=BATCH_SIZE,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41925f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for data in mnist:\n",
    "    print(data[1].shape)\n",
    "    show_mnist_image(data[0][10][0], data[1][0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a5edbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 genreator\n",
    "class Generator( nn.Module):\n",
    "    def __init__(self,z_dim):\n",
    "        super(Generator,self).__init__()\n",
    "        self.model=nn.Sequential(nn.Linear(z_dim,128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128,256),\n",
    "                      nn.BatchNorm1d(256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(256,512),\n",
    "                      nn.BatchNorm1d(512),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(512,1024),\n",
    "                      nn.BatchNorm1d(1024),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(1024,image_size*image_size),          \n",
    "                      nn.Tanh()\n",
    "                     )\n",
    "    def forward(self,z):\n",
    "        x=self.model(z)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cdd5c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 784])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_x=torch.randn(BATCH_SIZE,z_dim).to(device)\n",
    "print(g_x.shape)\n",
    "\n",
    "g_model=Generator(z_dim).to(device)\n",
    "g_model(g_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76b9c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 diacriminator model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,image_size):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.model=nn.Sequential(\n",
    "            nn.Linear(image_size**2,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,1),\n",
    "            nn.Sigmoid()\n",
    "        \n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x=self.model(x)\n",
    "        return x.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb8f60d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model=Discriminator(28).to(device)\n",
    "d_model(data[0].reshape(BATCH_SIZE,-1).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b573f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_optim=torch.optim.Adam(g_model.parameters(),1e-4)\n",
    "d_optim=torch.optim.Adam(d_model.parameters(),1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4a7b7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f670ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e60d3738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 ,step : 0 g_loss 0.7168797850608826 d_loss : 0.6974354386329651\n",
      "epoch 0 ,step : 100 g_loss 3.4340813159942627 d_loss : 0.057857267558574677\n",
      "epoch 1 ,step : 200 g_loss 2.7947185039520264 d_loss : 0.11535435914993286\n",
      "epoch 2 ,step : 300 g_loss 4.172830104827881 d_loss : 0.04975529760122299\n",
      "epoch 3 ,step : 400 g_loss 5.37674617767334 d_loss : 0.22458989918231964\n",
      "epoch 4 ,step : 500 g_loss 3.7307300567626953 d_loss : 0.1724877953529358\n",
      "epoch 5 ,step : 600 g_loss 2.9513959884643555 d_loss : 0.1292644739151001\n",
      "epoch 5 ,step : 700 g_loss 3.747551441192627 d_loss : 0.09711066633462906\n",
      "epoch 6 ,step : 800 g_loss 3.5994653701782227 d_loss : 0.270305871963501\n",
      "epoch 7 ,step : 900 g_loss 8.445976257324219 d_loss : 0.08116323500871658\n",
      "epoch 8 ,step : 1000 g_loss 6.448020935058594 d_loss : 0.23145557940006256\n",
      "epoch 9 ,step : 1100 g_loss 4.937501907348633 d_loss : 0.05940065532922745\n",
      "epoch 10 ,step : 1200 g_loss 7.2955169677734375 d_loss : 0.06850335001945496\n",
      "epoch 11 ,step : 1300 g_loss 5.009253978729248 d_loss : 0.07814342528581619\n",
      "epoch 11 ,step : 1400 g_loss 2.3316783905029297 d_loss : 0.18224775791168213\n",
      "epoch 12 ,step : 1500 g_loss 1.7785234451293945 d_loss : 0.3823484778404236\n",
      "epoch 13 ,step : 1600 g_loss 5.029975891113281 d_loss : 0.08684533089399338\n",
      "epoch 14 ,step : 1700 g_loss 3.3766584396362305 d_loss : 0.11389870196580887\n",
      "epoch 15 ,step : 1800 g_loss 3.10325026512146 d_loss : 0.15322786569595337\n",
      "epoch 16 ,step : 1900 g_loss 6.482583999633789 d_loss : 0.18383407592773438\n",
      "epoch 17 ,step : 2000 g_loss 2.903801202774048 d_loss : 0.29760175943374634\n",
      "epoch 17 ,step : 2100 g_loss 1.7834455966949463 d_loss : 0.38081803917884827\n",
      "epoch 18 ,step : 2200 g_loss 2.2920665740966797 d_loss : 0.18565189838409424\n",
      "epoch 19 ,step : 2300 g_loss 4.179546356201172 d_loss : 0.13367649912834167\n",
      "epoch 20 ,step : 2400 g_loss 2.6876463890075684 d_loss : 0.19667795300483704\n",
      "epoch 21 ,step : 2500 g_loss 3.950608968734741 d_loss : 0.16430871188640594\n",
      "epoch 22 ,step : 2600 g_loss 5.059207916259766 d_loss : 0.19755645096302032\n",
      "epoch 23 ,step : 2700 g_loss 2.6633431911468506 d_loss : 0.3293796181678772\n",
      "epoch 23 ,step : 2800 g_loss 2.2570605278015137 d_loss : 0.22381526231765747\n",
      "epoch 24 ,step : 2900 g_loss 3.4483413696289062 d_loss : 0.1990220844745636\n",
      "epoch 25 ,step : 3000 g_loss 4.89078426361084 d_loss : 0.23833250999450684\n",
      "epoch 26 ,step : 3100 g_loss 2.7986814975738525 d_loss : 0.2640724182128906\n",
      "epoch 27 ,step : 3200 g_loss 3.5526070594787598 d_loss : 0.27493685483932495\n",
      "epoch 28 ,step : 3300 g_loss 3.191063404083252 d_loss : 0.15764012932777405\n",
      "epoch 29 ,step : 3400 g_loss 2.1937665939331055 d_loss : 0.2952929139137268\n",
      "epoch 29 ,step : 3500 g_loss 2.2741904258728027 d_loss : 0.2903063893318176\n",
      "epoch 30 ,step : 3600 g_loss 2.001495838165283 d_loss : 0.5035447478294373\n",
      "epoch 31 ,step : 3700 g_loss 3.6550631523132324 d_loss : 0.25234276056289673\n",
      "epoch 32 ,step : 3800 g_loss 3.5547051429748535 d_loss : 0.3162950575351715\n",
      "epoch 33 ,step : 3900 g_loss 3.0260281562805176 d_loss : 0.2663128972053528\n",
      "epoch 34 ,step : 4000 g_loss 1.8857862949371338 d_loss : 0.3007603585720062\n",
      "epoch 35 ,step : 4100 g_loss 2.6639232635498047 d_loss : 0.22668209671974182\n",
      "epoch 35 ,step : 4200 g_loss 1.8574596643447876 d_loss : 0.3662193715572357\n",
      "epoch 36 ,step : 4300 g_loss 3.2393429279327393 d_loss : 0.3112046420574188\n",
      "epoch 37 ,step : 4400 g_loss 2.9239344596862793 d_loss : 0.16501419246196747\n",
      "epoch 38 ,step : 4500 g_loss 1.9679522514343262 d_loss : 0.29046642780303955\n",
      "epoch 39 ,step : 4600 g_loss 1.9335620403289795 d_loss : 0.2916073799133301\n",
      "epoch 40 ,step : 4700 g_loss 1.891355276107788 d_loss : 0.42226195335388184\n",
      "epoch 41 ,step : 4800 g_loss 1.888899326324463 d_loss : 0.30628496408462524\n",
      "epoch 41 ,step : 4900 g_loss 2.3702125549316406 d_loss : 0.35568752884864807\n",
      "epoch 42 ,step : 5000 g_loss 2.367532730102539 d_loss : 0.256580114364624\n",
      "epoch 43 ,step : 5100 g_loss 2.576202869415283 d_loss : 0.26784807443618774\n",
      "epoch 44 ,step : 5200 g_loss 2.434180974960327 d_loss : 0.2539520561695099\n",
      "epoch 45 ,step : 5300 g_loss 0.5209459066390991 d_loss : 0.8068275451660156\n",
      "epoch 46 ,step : 5400 g_loss 2.5390982627868652 d_loss : 0.31136631965637207\n",
      "epoch 47 ,step : 5500 g_loss 2.247666597366333 d_loss : 0.6948662996292114\n",
      "epoch 47 ,step : 5600 g_loss 2.7381434440612793 d_loss : 0.30022042989730835\n",
      "epoch 48 ,step : 5700 g_loss 4.302708625793457 d_loss : 0.22650127112865448\n",
      "epoch 49 ,step : 5800 g_loss 3.1031999588012695 d_loss : 0.19441105425357819\n",
      "epoch 50 ,step : 5900 g_loss 1.5729551315307617 d_loss : 0.5418944358825684\n",
      "epoch 51 ,step : 6000 g_loss 1.3208359479904175 d_loss : 0.3524215817451477\n",
      "epoch 52 ,step : 6100 g_loss 1.4837992191314697 d_loss : 0.5420188903808594\n",
      "epoch 52 ,step : 6200 g_loss 1.253283143043518 d_loss : 0.4816127121448517\n",
      "epoch 53 ,step : 6300 g_loss 2.572854995727539 d_loss : 0.2907183766365051\n",
      "epoch 54 ,step : 6400 g_loss 2.635932683944702 d_loss : 0.24617056548595428\n",
      "epoch 55 ,step : 6500 g_loss 1.6362013816833496 d_loss : 0.3009878396987915\n",
      "epoch 56 ,step : 6600 g_loss 1.5181670188903809 d_loss : 0.5141122341156006\n",
      "epoch 57 ,step : 6700 g_loss 1.9108644723892212 d_loss : 0.5157004594802856\n",
      "epoch 58 ,step : 6800 g_loss 1.3379863500595093 d_loss : 0.33499693870544434\n",
      "epoch 58 ,step : 6900 g_loss 1.726970911026001 d_loss : 0.28426966071128845\n",
      "epoch 59 ,step : 7000 g_loss 2.0839085578918457 d_loss : 0.2161490023136139\n",
      "epoch 60 ,step : 7100 g_loss 2.444088935852051 d_loss : 0.2927696704864502\n",
      "epoch 61 ,step : 7200 g_loss 1.473433494567871 d_loss : 0.3751366138458252\n",
      "epoch 62 ,step : 7300 g_loss 1.9008349180221558 d_loss : 0.4917698800563812\n",
      "epoch 63 ,step : 7400 g_loss 1.6829502582550049 d_loss : 0.3498736619949341\n",
      "epoch 64 ,step : 7500 g_loss 1.681158185005188 d_loss : 0.8028340935707092\n",
      "epoch 64 ,step : 7600 g_loss 0.8169249296188354 d_loss : 0.668433666229248\n",
      "epoch 65 ,step : 7700 g_loss 1.755063533782959 d_loss : 0.30878889560699463\n",
      "epoch 66 ,step : 7800 g_loss 1.2437961101531982 d_loss : 0.4716872572898865\n",
      "epoch 67 ,step : 7900 g_loss 1.1760997772216797 d_loss : 0.4562738537788391\n",
      "epoch 68 ,step : 8000 g_loss 1.2652592658996582 d_loss : 0.43750178813934326\n",
      "epoch 69 ,step : 8100 g_loss 1.096911907196045 d_loss : 0.6390000581741333\n",
      "epoch 70 ,step : 8200 g_loss 1.491410255432129 d_loss : 0.5857166051864624\n",
      "epoch 70 ,step : 8300 g_loss 1.4617754220962524 d_loss : 0.44582679867744446\n",
      "epoch 71 ,step : 8400 g_loss 1.372220516204834 d_loss : 0.4156903028488159\n",
      "epoch 72 ,step : 8500 g_loss 1.5878289937973022 d_loss : 0.3546684980392456\n",
      "epoch 73 ,step : 8600 g_loss 1.1817243099212646 d_loss : 0.5164732336997986\n",
      "epoch 74 ,step : 8700 g_loss 1.1765227317810059 d_loss : 0.45482686161994934\n",
      "epoch 75 ,step : 8800 g_loss 1.1433786153793335 d_loss : 0.4421226382255554\n",
      "epoch 76 ,step : 8900 g_loss 1.1966784000396729 d_loss : 0.5124329924583435\n",
      "epoch 76 ,step : 9000 g_loss 1.6453022956848145 d_loss : 0.39351892471313477\n",
      "epoch 77 ,step : 9100 g_loss 1.507843255996704 d_loss : 0.3859667181968689\n",
      "epoch 78 ,step : 9200 g_loss 1.7914996147155762 d_loss : 0.4032730460166931\n",
      "epoch 79 ,step : 9300 g_loss 1.4792087078094482 d_loss : 0.49091365933418274\n",
      "epoch 80 ,step : 9400 g_loss 1.6833133697509766 d_loss : 0.26916348934173584\n",
      "epoch 81 ,step : 9500 g_loss 1.3342430591583252 d_loss : 0.3924891948699951\n",
      "epoch 82 ,step : 9600 g_loss 1.469778299331665 d_loss : 0.40218067169189453\n",
      "epoch 82 ,step : 9700 g_loss 1.4196875095367432 d_loss : 0.3420141935348511\n",
      "epoch 83 ,step : 9800 g_loss 1.6900036334991455 d_loss : 0.5326682329177856\n",
      "epoch 84 ,step : 9900 g_loss 1.413212537765503 d_loss : 0.35144180059432983\n",
      "epoch 85 ,step : 10000 g_loss 1.5241183042526245 d_loss : 0.4382885992527008\n",
      "epoch 86 ,step : 10100 g_loss 1.33514404296875 d_loss : 0.4398556053638458\n",
      "epoch 87 ,step : 10200 g_loss 1.6653556823730469 d_loss : 0.34047073125839233\n",
      "epoch 88 ,step : 10300 g_loss 0.8151270151138306 d_loss : 0.6417012214660645\n",
      "epoch 88 ,step : 10400 g_loss 1.2638530731201172 d_loss : 0.3933068513870239\n",
      "epoch 89 ,step : 10500 g_loss 0.8733533620834351 d_loss : 0.535742998123169\n",
      "epoch 90 ,step : 10600 g_loss 2.1407086849212646 d_loss : 0.28053760528564453\n",
      "epoch 91 ,step : 10700 g_loss 1.336432933807373 d_loss : 0.5469411015510559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92 ,step : 10800 g_loss 1.5993343591690063 d_loss : 0.4692096710205078\n",
      "epoch 93 ,step : 10900 g_loss 1.4694548845291138 d_loss : 0.356439471244812\n",
      "epoch 94 ,step : 11000 g_loss 1.6345984935760498 d_loss : 0.27247190475463867\n",
      "epoch 94 ,step : 11100 g_loss 1.1210970878601074 d_loss : 0.469886839389801\n",
      "epoch 95 ,step : 11200 g_loss 1.174674391746521 d_loss : 0.7410930395126343\n",
      "epoch 96 ,step : 11300 g_loss 1.618743896484375 d_loss : 0.2906593084335327\n",
      "epoch 97 ,step : 11400 g_loss 1.5202062129974365 d_loss : 0.5828827023506165\n",
      "epoch 98 ,step : 11500 g_loss 1.5067031383514404 d_loss : 0.3210493326187134\n",
      "epoch 99 ,step : 11600 g_loss 1.0022518634796143 d_loss : 0.5199887752532959\n",
      "epoch 100 ,step : 11700 g_loss 1.6480638980865479 d_loss : 0.38166382908821106\n",
      "epoch 100 ,step : 11800 g_loss 2.2795538902282715 d_loss : 0.22390852868556976\n",
      "epoch 101 ,step : 11900 g_loss 1.433991551399231 d_loss : 0.47995099425315857\n",
      "epoch 102 ,step : 12000 g_loss 2.6949236392974854 d_loss : 0.3187396228313446\n",
      "epoch 103 ,step : 12100 g_loss 1.8100398778915405 d_loss : 0.2978011965751648\n",
      "epoch 104 ,step : 12200 g_loss 1.1360410451889038 d_loss : 0.43699878454208374\n",
      "epoch 105 ,step : 12300 g_loss 1.4392116069793701 d_loss : 0.352483332157135\n",
      "epoch 105 ,step : 12400 g_loss 1.971705436706543 d_loss : 0.2611149549484253\n",
      "epoch 106 ,step : 12500 g_loss 1.968935251235962 d_loss : 0.20759376883506775\n",
      "epoch 107 ,step : 12600 g_loss 2.376525402069092 d_loss : 0.2156306654214859\n",
      "epoch 108 ,step : 12700 g_loss 1.6907265186309814 d_loss : 0.33774513006210327\n",
      "epoch 109 ,step : 12800 g_loss 2.09529972076416 d_loss : 0.6615724563598633\n",
      "epoch 110 ,step : 12900 g_loss 1.912480115890503 d_loss : 0.371443510055542\n",
      "epoch 111 ,step : 13000 g_loss 1.759110927581787 d_loss : 0.5158081650733948\n",
      "epoch 111 ,step : 13100 g_loss 1.1948939561843872 d_loss : 0.47110241651535034\n",
      "epoch 112 ,step : 13200 g_loss 1.4085739850997925 d_loss : 0.42171967029571533\n",
      "epoch 113 ,step : 13300 g_loss 1.868944525718689 d_loss : 0.35985124111175537\n",
      "epoch 114 ,step : 13400 g_loss 1.9045835733413696 d_loss : 0.3153063654899597\n",
      "epoch 115 ,step : 13500 g_loss 1.226750135421753 d_loss : 0.4074036180973053\n",
      "epoch 116 ,step : 13600 g_loss 1.4532310962677002 d_loss : 0.4652845859527588\n",
      "epoch 117 ,step : 13700 g_loss 1.2987394332885742 d_loss : 0.5562168955802917\n",
      "epoch 117 ,step : 13800 g_loss 1.3898881673812866 d_loss : 0.40017974376678467\n",
      "epoch 118 ,step : 13900 g_loss 1.5367469787597656 d_loss : 0.38479024171829224\n",
      "epoch 119 ,step : 14000 g_loss 1.7335841655731201 d_loss : 0.43591076135635376\n",
      "epoch 120 ,step : 14100 g_loss 1.4332525730133057 d_loss : 0.5516245365142822\n",
      "epoch 121 ,step : 14200 g_loss 1.2521982192993164 d_loss : 0.34493663907051086\n",
      "epoch 122 ,step : 14300 g_loss 1.7248108386993408 d_loss : 0.3382796347141266\n",
      "epoch 123 ,step : 14400 g_loss 1.6202986240386963 d_loss : 0.3349142074584961\n",
      "epoch 123 ,step : 14500 g_loss 1.1448293924331665 d_loss : 0.43651697039604187\n",
      "epoch 124 ,step : 14600 g_loss 1.7474074363708496 d_loss : 0.5015562772750854\n",
      "epoch 125 ,step : 14700 g_loss 1.1391993761062622 d_loss : 0.6090540885925293\n",
      "epoch 126 ,step : 14800 g_loss 1.1270523071289062 d_loss : 0.6687873005867004\n",
      "epoch 127 ,step : 14900 g_loss 1.0280183553695679 d_loss : 0.6273729801177979\n",
      "epoch 128 ,step : 15000 g_loss 1.3107404708862305 d_loss : 0.5175061225891113\n",
      "epoch 129 ,step : 15100 g_loss 0.8507099151611328 d_loss : 0.6122593879699707\n",
      "epoch 129 ,step : 15200 g_loss 1.334446668624878 d_loss : 0.38506051898002625\n",
      "epoch 130 ,step : 15300 g_loss 1.2505158185958862 d_loss : 0.3493115305900574\n",
      "epoch 131 ,step : 15400 g_loss 1.5010876655578613 d_loss : 0.4071057140827179\n",
      "epoch 132 ,step : 15500 g_loss 1.441352367401123 d_loss : 0.3036506175994873\n",
      "epoch 133 ,step : 15600 g_loss 1.0751667022705078 d_loss : 0.5631154775619507\n",
      "epoch 134 ,step : 15700 g_loss 1.7279044389724731 d_loss : 0.3262583017349243\n",
      "epoch 135 ,step : 15800 g_loss 1.8145273923873901 d_loss : 0.36970290541648865\n",
      "epoch 135 ,step : 15900 g_loss 1.558176040649414 d_loss : 0.4109257459640503\n",
      "epoch 136 ,step : 16000 g_loss 1.226692795753479 d_loss : 0.41789835691452026\n",
      "epoch 137 ,step : 16100 g_loss 1.3398613929748535 d_loss : 0.45433345437049866\n",
      "epoch 138 ,step : 16200 g_loss 1.274824619293213 d_loss : 0.44183585047721863\n",
      "epoch 139 ,step : 16300 g_loss 1.8155537843704224 d_loss : 0.3560373783111572\n",
      "epoch 140 ,step : 16400 g_loss 1.441688060760498 d_loss : 0.42969390749931335\n",
      "epoch 141 ,step : 16500 g_loss 2.0308761596679688 d_loss : 0.34167250990867615\n",
      "epoch 141 ,step : 16600 g_loss 1.3008155822753906 d_loss : 0.4280252456665039\n",
      "epoch 142 ,step : 16700 g_loss 1.271411418914795 d_loss : 0.38515505194664\n",
      "epoch 143 ,step : 16800 g_loss 1.4440996646881104 d_loss : 0.4885290861129761\n",
      "epoch 144 ,step : 16900 g_loss 1.4170595407485962 d_loss : 0.43080204725265503\n",
      "epoch 145 ,step : 17000 g_loss 1.3417227268218994 d_loss : 0.4333934783935547\n",
      "epoch 146 ,step : 17100 g_loss 1.525183916091919 d_loss : 0.3626974821090698\n",
      "epoch 147 ,step : 17200 g_loss 1.3387527465820312 d_loss : 0.35362207889556885\n",
      "epoch 147 ,step : 17300 g_loss 1.441857099533081 d_loss : 0.45579203963279724\n",
      "epoch 148 ,step : 17400 g_loss 1.5768846273422241 d_loss : 0.4109010100364685\n",
      "epoch 149 ,step : 17500 g_loss 1.8883311748504639 d_loss : 0.36388325691223145\n",
      "epoch 150 ,step : 17600 g_loss 1.4210789203643799 d_loss : 0.374225378036499\n",
      "epoch 151 ,step : 17700 g_loss 1.7635345458984375 d_loss : 0.3094017505645752\n",
      "epoch 152 ,step : 17800 g_loss 1.5363374948501587 d_loss : 0.283458948135376\n",
      "epoch 152 ,step : 17900 g_loss 1.3986942768096924 d_loss : 0.38297855854034424\n",
      "epoch 153 ,step : 18000 g_loss 2.1768903732299805 d_loss : 0.38780176639556885\n",
      "epoch 154 ,step : 18100 g_loss 1.4727280139923096 d_loss : 0.47897928953170776\n",
      "epoch 155 ,step : 18200 g_loss 2.2358412742614746 d_loss : 0.41589677333831787\n",
      "epoch 156 ,step : 18300 g_loss 1.465484857559204 d_loss : 0.44332438707351685\n",
      "epoch 157 ,step : 18400 g_loss 1.1253507137298584 d_loss : 0.4908001124858856\n",
      "epoch 158 ,step : 18500 g_loss 1.4845268726348877 d_loss : 0.48770397901535034\n",
      "epoch 158 ,step : 18600 g_loss 1.8286175727844238 d_loss : 0.2794816493988037\n",
      "epoch 159 ,step : 18700 g_loss 1.831526279449463 d_loss : 0.35542452335357666\n",
      "epoch 160 ,step : 18800 g_loss 1.7249040603637695 d_loss : 0.3259088099002838\n",
      "epoch 161 ,step : 18900 g_loss 1.848286509513855 d_loss : 0.2839498519897461\n",
      "epoch 162 ,step : 19000 g_loss 1.4425280094146729 d_loss : 0.43698954582214355\n",
      "epoch 163 ,step : 19100 g_loss 1.6167832612991333 d_loss : 0.4363774061203003\n",
      "epoch 164 ,step : 19200 g_loss 2.002133846282959 d_loss : 0.4984446167945862\n",
      "epoch 164 ,step : 19300 g_loss 2.1274969577789307 d_loss : 0.26166707277297974\n",
      "epoch 165 ,step : 19400 g_loss 1.9757858514785767 d_loss : 0.3272862434387207\n",
      "epoch 166 ,step : 19500 g_loss 1.9232399463653564 d_loss : 0.5136124491691589\n",
      "epoch 167 ,step : 19600 g_loss 1.7150648832321167 d_loss : 0.37392351031303406\n",
      "epoch 168 ,step : 19700 g_loss 1.9521143436431885 d_loss : 0.39051786065101624\n",
      "epoch 169 ,step : 19800 g_loss 3.0493688583374023 d_loss : 0.289128839969635\n",
      "epoch 170 ,step : 19900 g_loss 1.6817548274993896 d_loss : 0.3925262689590454\n",
      "epoch 170 ,step : 20000 g_loss 2.2739334106445312 d_loss : 0.28296488523483276\n",
      "epoch 171 ,step : 20100 g_loss 1.0924506187438965 d_loss : 0.5776921510696411\n",
      "epoch 172 ,step : 20200 g_loss 1.565272569656372 d_loss : 0.4520341157913208\n",
      "epoch 173 ,step : 20300 g_loss 1.9974631071090698 d_loss : 0.3514367341995239\n",
      "epoch 174 ,step : 20400 g_loss 1.2209278345108032 d_loss : 0.434761643409729\n",
      "epoch 175 ,step : 20500 g_loss 1.3527939319610596 d_loss : 0.5571606755256653\n",
      "epoch 176 ,step : 20600 g_loss 1.2474236488342285 d_loss : 0.5511546730995178\n",
      "epoch 176 ,step : 20700 g_loss 1.644395112991333 d_loss : 0.46899932622909546\n",
      "epoch 177 ,step : 20800 g_loss 1.830744981765747 d_loss : 0.4555521011352539\n",
      "epoch 178 ,step : 20900 g_loss 1.4737690687179565 d_loss : 0.6814743280410767\n",
      "epoch 179 ,step : 21000 g_loss 1.6964586973190308 d_loss : 0.3480364680290222\n",
      "epoch 180 ,step : 21100 g_loss 2.028590679168701 d_loss : 0.4383710026741028\n",
      "epoch 181 ,step : 21200 g_loss 2.740206241607666 d_loss : 0.3996189534664154\n",
      "epoch 182 ,step : 21300 g_loss 1.7094264030456543 d_loss : 0.4442669749259949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 182 ,step : 21400 g_loss 1.3306434154510498 d_loss : 0.5133821368217468\n",
      "epoch 183 ,step : 21500 g_loss 1.3176958560943604 d_loss : 0.42207908630371094\n",
      "epoch 184 ,step : 21600 g_loss 1.4129407405853271 d_loss : 0.39676666259765625\n",
      "epoch 185 ,step : 21700 g_loss 1.4175748825073242 d_loss : 0.42117616534233093\n",
      "epoch 186 ,step : 21800 g_loss 1.6721432209014893 d_loss : 0.570063054561615\n",
      "epoch 187 ,step : 21900 g_loss 1.3310468196868896 d_loss : 0.5918399095535278\n",
      "epoch 188 ,step : 22000 g_loss 2.025338888168335 d_loss : 0.3992811441421509\n",
      "epoch 188 ,step : 22100 g_loss 2.296290397644043 d_loss : 0.3439684510231018\n",
      "epoch 189 ,step : 22200 g_loss 1.7932287454605103 d_loss : 0.33150947093963623\n",
      "epoch 190 ,step : 22300 g_loss 1.403996229171753 d_loss : 0.5008110404014587\n",
      "epoch 191 ,step : 22400 g_loss 2.3831825256347656 d_loss : 0.2999432682991028\n",
      "epoch 192 ,step : 22500 g_loss 2.180297374725342 d_loss : 0.34284043312072754\n",
      "epoch 193 ,step : 22600 g_loss 1.1214098930358887 d_loss : 0.4404413104057312\n",
      "epoch 194 ,step : 22700 g_loss 2.076892852783203 d_loss : 0.3048030734062195\n",
      "epoch 194 ,step : 22800 g_loss 2.20468807220459 d_loss : 0.40295571088790894\n",
      "epoch 195 ,step : 22900 g_loss 2.8943216800689697 d_loss : 0.24614275991916656\n",
      "epoch 196 ,step : 23000 g_loss 2.009378433227539 d_loss : 0.3926195502281189\n",
      "epoch 197 ,step : 23100 g_loss 2.306434392929077 d_loss : 0.21540199220180511\n",
      "epoch 198 ,step : 23200 g_loss 1.9602097272872925 d_loss : 0.2949262261390686\n",
      "epoch 199 ,step : 23300 g_loss 1.7549328804016113 d_loss : 0.3701763153076172\n"
     ]
    }
   ],
   "source": [
    "index=0\n",
    "for epoch in range(EPOCHS):\n",
    "    for data,label in mnist:\n",
    "        x=data.reshape(BATCH_SIZE,-1).to(device)\n",
    "        # 5.1 生成器训练 generator\n",
    "        z=torch.randn(BATCH_SIZE,z_dim).to(device)\n",
    "        \n",
    "        x_fake=g_model(z)\n",
    "        \n",
    "        ones=torch.ones(BATCH_SIZE).to(device)\n",
    "        zeros=torch.zeros(BATCH_SIZE).to(device)\n",
    "        \n",
    "        g_optim.zero_grad()\n",
    "        g_loss=loss_fn(d_model(x_fake),ones)\n",
    "        g_loss.backward()\n",
    "        g_optim.step()\n",
    "        \n",
    "        # 5.2 判别器训练\n",
    "        # discriminator\n",
    "        y_true=d_model(x)\n",
    "        y_false=d_model(x_fake.detach())\n",
    "        d_optim.zero_grad()\n",
    "        d_loss=0.5*(loss_fn(y_true,ones)+loss_fn(y_false,zeros))\n",
    "        d_loss.backward()\n",
    "        d_optim.step()\n",
    "        \n",
    "        if index%100==0:\n",
    "            print(f\"epoch {epoch} ,step : {index} g_loss {g_loss} d_loss : {d_loss}\")\n",
    "            if index%100==0:\n",
    "                os.makedirs(\"image\",exist_ok=True)\n",
    "                image=x_fake.reshape(BATCH_SIZE,1,28,28).data[:25]\n",
    "                save_image(image,\"image/%d.png\" % index,normalize=True)\n",
    "        index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b296ead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts",
   "language": "python",
   "name": "tts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
